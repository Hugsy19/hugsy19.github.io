<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>深度学习(11)：序列模型 - Cornfield Chase</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#B481BB"><meta name="application-name" content="Hugsy&#039;s Blog"><meta name="msapplication-TileImage" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><meta name="msapplication-TileColor" content="#B481BB"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hugsy&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><meta name="description" content="采用循环神经网络能够建立各种各样的序列模型（Sequence Model）。加入一些注意力机制，能够使这些序列模型更加强大。"><meta property="og:type" content="blog"><meta property="og:title" content="深度学习(11)：序列模型"><meta property="og:url" content="https://hugsy.top/2018/03/09/ML/deep_learning_11/"><meta property="og:site_name" content="Cornfield Chase"><meta property="og:description" content="采用循环神经网络能够建立各种各样的序列模型（Sequence Model）。加入一些注意力机制，能够使这些序列模型更加强大。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"><meta property="article:published_time" content="2018-03-08T16:00:00.000Z"><meta property="article:modified_time" content="2022-06-08T14:40:25.723Z"><meta property="article:author" content="Hugsy"><meta property="article:tag" content="ML"><meta property="article:tag" content="Coursera"><meta property="article:tag" content="Deep Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hugsy.top/2018/03/09/ML/deep_learning_11/"},"headline":"深度学习(11)：序列模型","image":["https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"],"datePublished":"2018-03-08T16:00:00.000Z","dateModified":"2022-06-08T14:40:25.723Z","author":{"@type":"Person","name":"Hugsy"},"description":"采用循环神经网络能够建立各种各样的序列模型（Sequence Model）。加入一些注意力机制，能够使这些序列模型更加强大。"}</script><link rel="canonical" href="https://hugsy.top/2018/03/09/ML/deep_learning_11/"><link rel="alternate" href="/atom.xml" title="Cornfield Chase" type="application/atom+xml"><link rel="icon" href="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?7b65ce26b5ae8dae153d7b4d53214ba4";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/logo.svg" alt="Cornfield Chase" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/tags/CS/">CS</a><a class="navbar-item" href="/tags/EE/">EE</a><a class="navbar-item" href="/tags/ML/">ML</a><a class="navbar-item" href="/tags/ME/">ME</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png" alt="深度学习(11)：序列模型"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-03-08T16:00:00.000Z" title="3/9/2018, 12:00:00 AM">2018-03-09</time>发表</span><span class="level-item"><time dateTime="2022-06-08T14:40:25.723Z" title="6/8/2022, 10:40:25 PM">2022-06-08</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">32 分钟读完 (大约4840个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">深度学习(11)：序列模型</h1><div class="content"><p>采用循环神经网络能够建立各种各样的<strong>序列模型（Sequence Model）</strong>。加入一些注意力机制，能够使这些序列模型更加强大。</p>
<span id="more"></span>
<h2 id="Seq2Seq模型"><a href="#Seq2Seq模型" class="headerlink" title="Seq2Seq模型"></a>Seq2Seq模型</h2><p>2014年Cho等人在论文[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a>]中首次提出了<strong>Seq2Seq（Sequence-to-Sequence）</strong>模型。从机器翻译到语音识别，这种模型能够在各种序列到序列的转换问题中得到应用。</p>
<p>一个Seq2Seq模型中可分成<strong>编码器（Encoder）</strong>和<strong>译码器（Decoder）</strong>两部分，它们通常是两个不同的神经网络。如下图是谷歌机器翻译团队的Sutskever等人2014年在论文[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.3215.pdf">Sequence to Sequence Learning with Neural Networks</a>]中提出的机器翻译模型：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163124.png" alt="机器翻译"></p>
<p>上面法语中的词依次输入作为编码器的RNN的时间步中，这个RNN可以是GRU或LSTM。将编码器的最后输出作为译码器的输入，译码器也是一个RNN，训练译码器作出正确的翻译结果。</p>
<p>这种Enconder-Decoder的结构，也可以应用在<strong>图像标注（Image Caption）</strong>上。2014年百度研究所的毛俊骅等人在论文[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1412.6632.pdf">DDeep Captioning with Multimodal Recurrent Neural Networks (m-RNN)</a>]中提出了如下图中的结构：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163141.png" alt="图像标注"></p>
<p>上面将图像输入了一个作为编码器的AlexNet结构的CNN中，最后的Softmax换成一个RNN作为译码器，训练网络输出图像的标注结果。</p>
<p>另外两篇论文[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1411.4555.pdf">Show and Tell: A Neural Image Caption Generator</a>]和 [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1412.2306.pdf">Deep Visual-Semantic Alignments for Generating Image Descriptions</a>]中， 也提到了这种结构。</p>
<p>机器翻译用到的Seq2Seq模型中，译码器所做的工作与前面讲过的语言模型的采样过程类似，只不过在机器翻译中，用编码器的输出代替语言模型中的$0$作为译码器中第一个时间步的输入，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163158.png" alt="类比"></p>
<p>换句话说，机器翻译其实是一个输入为法语的条件下，希望以对应的英语作为输出的语言模型，所以机器翻译的过程也就相当于建立一个**条件语言模型（Conditional Language Model)**的过程。</p>
<p>采用大量的数据训练好一个机器翻译系统后，对于一个相同的句子，由于译码器进行的是随机采样过程，输出的可能会是多种或好或坏的结果：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163213.png" alt="多种结果"></p>
<p>所以对训练好的机器翻译系统，还需要加入一些算法，使其总是输出最好的翻译结果。</p>
<p>考虑直接使用CS中的<strong>贪心搜索（Greedy Search）</strong>算法，让译码器中每个时间步都取概率最大的那个词，得到的翻译结果还是会不尽人意。</p>
<h2 id="集束搜索"><a href="#集束搜索" class="headerlink" title="集束搜索"></a>集束搜索</h2><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><p>Seq2Seq模型中，译码器的输出结果总是在RNN中采样后得到，造成模型训练完毕后，得到测试的结果参差不齐，<strong>集束搜索（Beam Search）</strong>算法能很好地解决这个问题。这里还是以机器翻译的例子来说明这种算法。</p>
<p>将集束搜索算法运用到机器翻译系统的第一步，是设定一个<strong>束长（Bean Width）</strong>$B$，它代表了译码器中每个时间步的预选单词数量。如下图中$B = 3$，则将第一个时间步中预测出的概率最大的$3$个词作为首词的预选词，同时保存它们的概率值大小$p(y^{\langle 1 \rangle} \mid x)$:</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163226.png" alt="Step 1"></p>
<p>如果第一步得到的三个预选词分别为“in”、“jane”和“September”，如下图所示，则第二步中，分别将三个预选词作为第一个时间步的预测结果$y^{\langle 1 \rangle}$输入第二个时间步，得到预测结果${\hat y}^{\langle 2 \rangle}$，也就是条件概率值$p({\hat y}^{\langle 2 \rangle} \mid x, y^{\langle 1 \rangle})$:</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163242.png" alt="Step 2"></p>
<p>根据<strong>条件概率</strong>公式，有：$$p(y^{\langle 1 \rangle}, {\hat y}^{\langle 2 \rangle} \mid x) = p(y^{\langle 1 \rangle} \mid x) p({\hat y}^{\langle 2 \rangle} \mid x, y^{\langle 1 \rangle}) $$</p>
<p>分别以三个首词预选词作为$y^{\langle 1 \rangle}$进行计算，将得到$30000$个$p(y^{\langle 1 \rangle}, {\hat y}^{\langle 2 \rangle} \mid x)$。之后还是取其中概率值最大的$B = 3$个，作为对应首词条件下的第二个词的预选词。比如第二个词的预选词分别是“in”为首词条件下的“September”，”jane”为首词条件下的“is”和“visits”，这样的话首词的预选词就只剩下了“in”和“jane”而排除了“September”。后面的过程以此类推，最后将输出一个最优的翻译结果。</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>总的来说，集束搜索算法所做的工作就是找出符合以下公式的结果：$$ arg\ max\ \prod^{T_y}_{t = 1} p(y^{\langle t \rangle} \mid x, y^{\langle 1 \rangle},…,y^{\langle t-1 \rangle})$$<br>然而概率值都是小于$1$的值，多个概率值相乘后的结果的将会是一个极小的浮点值，累积到最后的效果不明显且在一般的计算机上达不到这样的计算精度。改进的方法，是取上式的$log$值并进行标准化：$$ arg\ max\ \frac{1}{T^{\alpha}_y} \sum^{T_y}_{t = 1} log \ p(y^{\langle t \rangle} \mid x, y^{\langle 1 \rangle},…,y^{\langle t-1 \rangle})$$<br>其中的$\alpha$是一个需要根据实际情况进行调节的超参数。</p>
<p>与CS中的精确查找算法–<strong>广度优先查找（Breadth First Search，BFS）</strong>、<strong>深度优先查找（Depth First Search，DFS）</strong>算法不同，集束搜索算法运行的速度虽然很快，但是并不保证能够精确地找到满足$arg\ max\ p(y \mid x)$的结果。</p>
<p>关于束长$B$的取值，较大的$B$值意味着同时考虑了更多的可能，最后的结果也可能会更好，但会带来巨大的计算成本；较小的$B$值减轻了计算成本的同时，也可能会使最后的结果变得糟糕。通常情况下，$B$值取一个$10$以下地值较为合适。还是要根据实际的应用场景，适当地选取。要注意的是，当$B = 1$时，这种算法就和贪心搜索算法没什么两样了。</p>
<h3 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h3><p>在前面的结构化机器学习项目课程中，已经了解过错误分析。集束搜索是一种<strong>启发式（Heuristic）</strong>搜索算法，它的输出结果不是总为最优的。结合Seq2Seq模型与集束搜索算法构建的机器翻译等系统出错时，差错到底是出现在前者的RNN还是后者的算法中，还是需要通过一些手段，来进行错误分析。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163259.png" alt="错误分析"></p>
<p>例如对图中的法语，发现机器翻译的结果$\hat y$与专业的人工翻译的结果$y^{*}$存在较大的差别。要找到错误的根源，首先将翻译没有差别的一部分“Jane visits Africa”分别作为译码器中其三个时间步的输入，得到第四个时间步的输出为“in”的概率$p(y^{*} \mid x)$和“last”的概率$p(\hat{y} \mid x)$，比较它们的大小并分析：</p>
<ul>
<li>若$p(y^{*} \mid x) \gt p(\hat{y} \mid x)$，说明是集束搜索时出现错误，没有选择到概率最大的词；</li>
<li>若$p(y^{*} \mid x) \le p(\hat{y} \mid x)$，说明是RNN模型的表现不够好，预测的第四个词为“in”的概率小于“last”。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163314.png" alt="分析表格"></p>
<p>分析过程中，可以建立一个如上所示的表格，提高错误查找效率。</p>
<h2 id="机器翻译评估：BLEU指标"><a href="#机器翻译评估：BLEU指标" class="headerlink" title="机器翻译评估：BLEU指标"></a>机器翻译评估：BLEU指标</h2><p>BLEU（Bilingual Evaluation Understudy）是一种用来评估机器翻译质量的指标，它早在2002年由Papineni等人在论文[<a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/P02-1040.pdf">BLEU: a Method for Automatic Evaluation of Machine Translation</a>]中提出。BLEU的设计思想与评判机器翻译好坏的思想是一致的：机器翻译的结果越接近专业的人工翻译，则评估的分值越高。</p>
<p>最原始的BLEU算法很简单：统计机器翻译结果中的每个单词在参考翻译中出现的次数作为分子，机器翻译结果的总词数作为分母。然而这样得到结果很容易出现错误。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163329.png" alt="原始BLEU"></p>
<p>如上图的例子中，机器翻译得到的结果是$7$个“the”，分母为$7$，每个“the”都在参考翻译中有出现，分子为$7$，得到翻译精确度为$1.0$，这显然是不对的。改进这种算法，将参考翻译中“the”出现的最高次数作为分子，机器翻译结果中“the”的出现次数作为分母，可得精度为$\frac{2}{7}$。</p>
<p>上面的方法是一个词一个词进行统计，这种以一个单词为单位的集合统称为<strong>uni-gram（一元组）</strong>。以uni-gram统计得到的精度$p_1$体现了翻译的充分性，也就是逐字逐句地翻译能力。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163343.png" alt="Bi-gram"></p>
<p>两个单词为单位的集合则称为<strong>bi-gram（二元组）</strong>，例如对以上机器翻译结果（$count$）及参考翻译（$count_{clip}$）以二元组统计有：</p>
<table>
<thead>
<tr>
<th>bi-gram</th>
<th>$count$</th>
<th>$count_{clip}$</th>
</tr>
</thead>
<tbody><tr>
<td>the cat</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>cat the</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>cat on</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>on the</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>the mat</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>Count</td>
<td>6</td>
<td>4</td>
</tr>
</tbody></table>
<p>根据上表，可得到机器翻译精度为$\frac{4}{6}$。</p>
<p>以此类推，以n个单词为单位的集合为<strong>n-gram（多元组）</strong>，采用n-gram统计的翻译精度$p_n$的计算公式为：$$p_n = \frac{\sum_{\text{n-gram} \in \hat{y}} count_{clip}(\text{n-gram})}{\sum_{\text{n-gram} \in \hat{y}} count(\text{n-gram})}$$</p>
<p>以n-gram统计得到的$p_n$体现了翻译的流畅度。将uni-gram下的$p_1$到n-gram下的$p_n$组合起来，对这$N$个值进行<strong>几何加权平均</strong>得到：$$p_{ave}=exp(\frac{1}{N}\sum_{i=1}^{N}log^{p_{n}})$$</p>
<p>此外，注意到采用n-gram时，机器翻译的结果在比参考翻译短的情况下，很容易得到较大的精度值。改进的方法是设置一个<strong>最佳匹配长度（Best Match Length）</strong>，机器翻译的结果未达到该最佳匹配长度时，则需要接受<strong>简短惩罚（Brevity Penalty，BP）</strong>：$$BP = \begin{cases} 1,  &amp; \text{(MT_length $\ge$ BM_length)} \\ exp(1 - \frac{\text{MT_length}}{\text{BM_length}}), &amp; \text{(MT_length $\lt$ BM_length)} \end{cases}$$<br>最后得到BLEU指标为：$$ BLEU = BP \times exp(\frac{1}{N}\sum_{i=1}^{N}log^{p_{n}}) $$</p>
<h2 id="注意力模型"><a href="#注意力模型" class="headerlink" title="注意力模型"></a>注意力模型</h2><p>人工翻译一大段文字时，一般都是阅读其中的一小部分后翻译出这一部分，在一小段时间里注意力只能集中在一小段文字上，而很难做到把整段读完后一口气翻译出来。用Seq2Seq模型构建的机器翻译系统中，输出结果的BLEU评分会随着输入序列长度的增加而下降，其中的道理就和这个差不多。</p>
<p>2014年Bahdanau等人在论文[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.0473.pdf">Neural Machine Translation by Jointly Learning to Align and Translate</a>]中提出了<strong>注意力模型（Attention Model）</strong>。最初只是用这种模型对机器翻译作出改进，之后其思想也在其他领域也得到了广泛应用，并成为深度学习领域最有影响力的思想之一。</p>
<p>注意力模型中，网络的示例结构如下所示：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163407.png" alt="注意力模型"></p>
<p>底层是一个双向循环神经网络，需要处理的序列作为它的输入。该网络中每一个时间步的激活$a^{\langle t’ \rangle}$中，都包含前向传播产生的和反向传播产生的激活：$$a^{\langle t’ \rangle} = ({\overrightarrow a}^{\langle t’ \rangle}, {\overleftarrow a}^{\langle t’ \rangle})$$</p>
<p>顶层是一个“多对多”结构的循环神经网络，第$t$个时间步以该网络中前一个时间步的激活$s^{\langle t-1 \rangle}$、输出$y^{\langle t-1 \rangle}$以及底层的BRNN中多个时间步的激活$c$作为输入。对第$t$个时间步的输入$c$有：$$c = \sum_{t’} {\alpha}^{\langle t,t’ \rangle}a^{\langle t’ \rangle} $$</p>
<p>其中的参数${\alpha}^{\langle t,t’ \rangle}$意味着顶层RNN中，第$t$个时间步输出的$y^{\langle t \rangle}$中，把多少“注意力”放在了底层BRNN的第$t’$个时间步的激活$a^{\langle t’ \rangle}$上。它总有：$$\sum_{t’} {\alpha}^{\langle t,t’ \rangle} = 1$$</p>
<p>为确保参数${\alpha}^{\langle t,t’ \rangle}$满足上式，常用Softmax单元来计算顶层RNN的第$t$个时间步对底层BRNN的第$t’$个时间步的激活的“注意力”：$${\alpha}^{\langle t,t’ \rangle} = \frac{exp(e^{\langle t,t’ \rangle})}{\sum_{t’=1}^{T_x} exp(e^{\langle t,t’ \rangle})} $$<br>其中的$e^{\langle t,t’ \rangle}$由顶层RNN的激活$s^{\langle t - 1 \rangle}$和底层BRNN的激活$a^{\langle t’ \rangle}$一起输入一个隐藏层中得到的，因为$e^{\langle t,t’ \rangle}$也就是${\alpha}^{\langle t,t’ \rangle}$的值明显与$s^{\langle t \rangle}$、$a^{\langle t’ \rangle}$有关，由于$s^{\langle t \rangle}$此时还是未知量，则取上一层的激活$s^{\langle t-1\rangle}$。在无法获知$s^{\langle t-1 \rangle}$、$a^{\langle t’ \rangle}$与$e^{\langle t,t’ \rangle}$之间的关系下，那就用一个神经网络来进行学习，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163425.png" alt="参数阿尔法"></p>
<p>要注意的是，该模型的运算成本将达到$N^2$。此外，在2015年Xu等人发表的论文[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1502.03044.pdf">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a>]中，这种模型也被应用到了图像标注中。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="语音识别"><a href="#语音识别" class="headerlink" title="语音识别"></a>语音识别</h3><p>在语音识别中，要做的是将输入的一段语音$x$转换为一段文字副本作为输出。<br><img src="https://wx1.sinaimg.cn/large/82e16446gy1fp95qtnapgj20ww0ajwhv.jpg" alt="语音识别"><br>曾经的语音识别系统都是采用人工设计出的<strong>音素（Phonemes）</strong>识别单元来构建，音素指的是一种语言中能区别两个词的最小语音单位。现在有了端对端深度学习，已经完美没有必要采用这种识别音素的方法实现语音识别。</p>
<p>采用深度学习方法训练语音识别系统的前提条件是拥有足够庞大的训练数据集。在学术界的研究中，3000小时的长度被认为是训练一个语音识别系统时，需要的较为合理的音频数据大小。而训练商用级别的语音识别系统，需要超过一万小时甚至十万小时以上的音频数据。</p>
<p>语音识别系统可以采用注意力模型来构建：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163440.png" alt="Attention-语音识别"></p>
<p>2006年Graves等人在论文[<a target="_blank" rel="noopener" href="http://people.idsia.ch/~santiago/papers/icml2006.pdf">Connectionist Temporal Classification: Labeling unsegmented sequence data with recurrent neural networks</a>]中提出了一种名为<strong>CTC（Connectionist Temporal Classification）</strong>损失函数计算方法，给语音识别系统的训练过程带来很大帮助。</p>
<p>由于输入的是音频数据，采用RNN建立的语音识别系统中将包含多个时间步，且整个网络中输出的数量往往是小于输入的数量的，也就是说不是每一个时间步都有对于的输出。而CTC的主要优点，是可对没有对齐的数据进行自动对齐。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163457.png" alt="CTC"></p>
<p>如上图中，以一句意为图中下面的句子，长度为10s频率为100Hz的语音作为输入，则这段语音序列可分为1000个部分，分别输入RNN的时间步中，而RNN可能不会将1000个作为输出。</p>
<p>CTC损失计算方法允许RNN输出一个如图中所示的结果，允许以“空白（Blank）”作为输出的同时，也会识别出词之间存在的“空格（Space）”标记，CTC还将把未被“空白”分隔的重复字符折叠起来。</p>
<p>关于CTC的更多细节详见论文内容。</p>
<h3 id="触发词检测"><a href="#触发词检测" class="headerlink" title="触发词检测"></a>触发词检测</h3><p><strong>触发词检测（Trigger Word Detection）</strong>现在已经被应用在各种语音助手以及智能音箱上。例如在Windows 10上能够设置微软小娜用指令“你好，小娜”进行唤醒，安卓手机上的Google Assistant则可以通过“OK，Google”唤醒。</p>
<p>想要训练一个触发词检测系统，同样需要有大量的标记好的训练数据。使用RNN训练语音识别系统实现触发词词检测的功能时，可以进行如下图所示的工作：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411163513.png" alt="触发词检测"></p>
<p>在以训练的语音数据中输入RNN中，将触发词结束后的一小段序列的标签设置为“$1$”，以此训练模型对触发词的检测。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="http://moo0c.study.163.com/course/2001280005?tid=2001391038#/info">吴恩达-序列模型-网易云课堂</a></li>
<li><a target="_blank" rel="noopener" href="https://www.coursera.org/learn/nlp-sequence-models/">Andrew Ng-Sequence Model-Coursera</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27766645">sequence to sequence model小记-知乎专栏</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28048246">seq2seq中的beam search算法过程-知乎专栏</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.csdn.net/qq_31584157/article/details/77709454">机器翻译自动评估-BLEU算法详解</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.csdn.net/xbinworld/article/details/54607525">深度学习方法：自然语言处理中的Attention Model注意力模型-csdn</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.csdn.net/luodongri/article/details/77005948">白话CTC算法讲解-csdn</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Hugsy19/MachineLearning">课程代码与资料-GitHub</a></li>
</ol>
<p>注：本文涉及的图片及资料均整理翻译自Andrew Ng的Deep Learning系列课程，版权归其所有。翻译整理水平有限，如有不妥的地方欢迎指出。</p>
<hr>
<p>更新历史：</p>
<ul>
<li>2018.03.11 完成初稿</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>深度学习(11)：序列模型</p><p><a href="https://hugsy.top/2018/03/09/ML/deep_learning_11/">https://hugsy.top/2018/03/09/ML/deep_learning_11/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hugsy</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2018-03-09</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-06-08</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/ML/">ML</a><a class="link-muted mr-2" rel="tag" href="/tags/Coursera/">Coursera</a><a class="link-muted mr-2" rel="tag" href="/tags/Deep-Learning/">Deep Learning</a></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><div class="social-share"></div><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210410180700.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210410180901.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/06/24/EE/android_shannon/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">【Android】香农APP</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/03/01/ML/deep_learning_10/"><span class="level-item">深度学习(10)：自然语言处理</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "c47d24380e8ba283d5db99d264d2e66d",
            repo: "Picbed",
            owner: "Hugsy19",
            clientID: "a321e46c668dc3d86c4f",
            clientSecret: "0ff9e81865b09e7511ef7ef17bb9596834b8fd95",
            admin: ["Hugsy19"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            proxy: "https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token",
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/logo.svg" alt="Cornfield Chase" height="28"></a><p class="is-size-7"><span>&copy; 2022 Hugsy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>
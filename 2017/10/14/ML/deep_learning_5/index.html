<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>深度学习(5)：TensorFlow - Cornfield Chase</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#B481BB"><meta name="application-name" content="Hugsy&#039;s Blog"><meta name="msapplication-TileImage" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><meta name="msapplication-TileColor" content="#B481BB"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hugsy&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><meta name="description" content="每次都从零开始全部靠自己去建立一个深层神经网络模型并不现实，借助现在众多流行的深度学习框架，能够高效地实现这些模型。TensorFlow便是其中之一。"><meta property="og:type" content="blog"><meta property="og:title" content="深度学习(5)：TensorFlow"><meta property="og:url" content="https://hugsy.top/2017/10/14/ML/deep_learning_5/"><meta property="og:site_name" content="Cornfield Chase"><meta property="og:description" content="每次都从零开始全部靠自己去建立一个深层神经网络模型并不现实，借助现在众多流行的深度学习框架，能够高效地实现这些模型。TensorFlow便是其中之一。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"><meta property="article:published_time" content="2017-10-13T16:00:00.000Z"><meta property="article:modified_time" content="2022-12-10T10:02:37.570Z"><meta property="article:author" content="Hugsy"><meta property="article:tag" content="ML"><meta property="article:tag" content="Python"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hugsy.top/2017/10/14/ML/deep_learning_5/"},"headline":"深度学习(5)：TensorFlow","image":["https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"],"datePublished":"2017-10-13T16:00:00.000Z","dateModified":"2022-12-10T10:02:37.570Z","author":{"@type":"Person","name":"Hugsy"},"description":"每次都从零开始全部靠自己去建立一个深层神经网络模型并不现实，借助现在众多流行的深度学习框架，能够高效地实现这些模型。TensorFlow便是其中之一。"}</script><link rel="canonical" href="https://hugsy.top/2017/10/14/ML/deep_learning_5/"><link rel="alternate" href="/atom.xml" title="Cornfield Chase" type="application/atom+xml"><link rel="icon" href="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?7b65ce26b5ae8dae153d7b4d53214ba4";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/logo.svg" alt="Cornfield Chase" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/tags/CS/">CS</a><a class="navbar-item" href="/tags/EE/">EE</a><a class="navbar-item" href="/tags/ML/">ML</a><a class="navbar-item" href="/tags/ME/">ME</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png" alt="深度学习(5)：TensorFlow"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2017-10-13T16:00:00.000Z" title="10/14/2017, 12:00:00 AM">2017-10-14</time>发表</span><span class="level-item"><time dateTime="2022-12-10T10:02:37.570Z" title="12/10/2022, 6:02:37 PM">2022-12-10</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span><span class="level-item">18 分钟读完 (大约2674个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">深度学习(5)：TensorFlow</h1><div class="content"><p>每次都从零开始全部靠自己去建立一个深层神经网络模型并不现实，借助现在众多流行的深度学习框架，能够高效地实现这些模型。<strong>TensorFlow</strong>便是其中之一。</p>
<span id="more"></span>

<h2 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h2><p>TensorFlow是Google基于DistBelief进行研发的第二代人工智能学习系统，是一个使用数据流图进行数值计算的开源软件库。其命名来源于本身的运行原理，Tensor(张量)意味着N维数组，Flow（流）意味着基于数据流图的计算，TensorFlow便意为张量从流图的一端流动到另一端计算过程。TensorFlow 中包含了一款强大的线性代数编译器XLA，这可以帮助TensorFlow代码在嵌入式处理器、CPU（Central Processing Unit）、GPU（Graphics Processing Unit）、TPU（Tensor Processing Unit）和其他硬件平台上尽可能快速地运行。</p>
<h3 id="版本选择"><a href="#版本选择" class="headerlink" title="版本选择"></a>版本选择</h3><p>TensorFlow分为CPU版和GPU版。GPU版需要有NVIDIA显卡的支持，TensorFlow程序通常在GPU上的运行速度明显高于CPU，查看设备是否配备了NVIDIA显卡方法另寻。</p>
<p>如果设备配备了NVIDIA显卡，还需根据显卡的具体型号，到<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-gpus">NVIDIA官方文档</a>上找到你的GPU，查看其该型号的N卡是否支持<strong>CUDA（Compute Unified Device Architecture）</strong>，以及CUDA算力（Computer Capability）。TensorFlow要求GPU的CUDA计算能力值达到3.0以上，否则比直接CPU上运算的效果相差不大。一些年份较早或比较低端的显卡达不到这个要求，这种情况下即使安装了GPU版本也还是会调用CPU运算，不会调用GPU。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>TensorFlow的Python版本一般直接使用pip命令进行安装，CPU版本的pip安装命令为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade tensorflow</span><br></pre></td></tr></table></figure>
<p>GPU版本为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade tensorflow-gpu</span><br></pre></td></tr></table></figure>

<p>安装GPU版本后想要用N卡正常运行，需要先安装<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA® Toolkit</a>和<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cudnn">cuDNN</a>，根据各自的平台进行下载安装。而且需要注意，下载安装的版本务必按照安装好的TensorFlow支持的版本来。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>安装完成后，打开在命令行或终端中激活Python，输入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Python</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">hello = tf.constant(<span class="string">&#x27;Hello, TensorFlow!&#x27;</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="built_in">print</span>(sess.run(hello))</span><br></pre></td></tr></table></figure>
<p>安装无误的话，最后将打印出熟悉的“Hello, TensorFlow!”。此外，如果安装的是GPU版，输入第三行代码后将显示你的GPU配置信息。</p>
<h2 id="实现MNIST手写数字识别"><a href="#实现MNIST手写数字识别" class="headerlink" title="实现MNIST手写数字识别"></a>实现MNIST手写数字识别</h2><h3 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h3><p>MNIST（Mixed National Institute of Standards and Technology database）是一个入门级的计算机视觉数据集，其中包含各种手写数字图片：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411154905.png" alt="MNIST"></p>
<p>上面的四张图的标签（labels）分别为5,0,4,1。</p>
<p>MNIST数据集被分为三部分：55000个训练样本（mnist.train),10000个测试样本（mnist.test),5000个验证集（mnist.validation)。每个样本由两部分组成，一个大小为28*28的手写数字图片像素值矩阵$x$以及它的标签$y$，标签$y$是用<strong>one-hot向量</strong>表示的，一张数字图片中的真实数字值n,将表示成一个只在第n维度的数字为1的10位维向量。例如，标签3用one—hot向量表示为$[0,0,0,1,0,0,0,0,0,0]$。one-hot编码多用在多分类问题上。</p>
<p>则整个训练样本中$X$（mnist.train.images）的大小为55000*784,$Y$（mnist.train.labels)的大小为55000*10。其中的数据都已经进行过标准化。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155340.png" alt="MNIST数据"></p>
<h3 id="Softmax回归"><a href="#Softmax回归" class="headerlink" title="Softmax回归"></a>Softmax回归</h3><p>Softmax回归模型是Logistic回归模型在多分类问题上的推广。为了收集证据以便将给定的图片划定到某个固定分类，首先对图片的像素值加权值w并求和，如果有很明显的证据表明一张图片中某些像素点会导致这张图片不属于这一类，则相应的权值为负数，反之权值为正。如下图所示，其中红色部分代表负数权值，蓝色部分代表正数权值。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155403.png" alt="加权求和"></p>
<p>训练过程中，为了排除输入中引入的干扰数据，还需要设定额外的偏执量b。其实就是进行简单的线性拟合：$${ \text{evidence} = w^TX + b}$$<br>其中参数矩阵$w$的大小为784*10,$b$的大小为10*1。和Logistic回归一样，其中的$w$、$b$还是直接初始化为0。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155421.png" alt="Softmax回归"></p>
<p>Softmax回归中，激活函数使用的是softmax函数：$$\sigma(z)_{j}=\frac{e^{z_{j}}}{\sum_{i=1}^m e^{z_{i}}}$$<br>损失函数也变为：$$\mathcal{L}(\hat y, y) =  - \sum^m_{i=1}y_i \log \hat y$$<br>随后使用小批量梯度下降法来求得参数的最优解。</p>
<h3 id="tensorflow实现"><a href="#tensorflow实现" class="headerlink" title="tensorflow实现"></a>tensorflow实现</h3><p>使用tensorflow来实现这个模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入要用到的库</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&quot;MNIST_data/&quot;</span>, one_hot = <span class="literal">True</span>) <span class="comment">#导入数据集</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化参数</span></span><br><span class="line">W = tf.Variable(tf.zeros([mnist.train.images.shape[<span class="number">1</span>],<span class="number">10</span>])) <span class="comment">#W初始化为0</span></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>])) <span class="comment">#b初始化为0</span></span><br><span class="line">costs = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立模型</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist.train.images.shape[<span class="number">1</span>]])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>]) <span class="comment">#建立训练集占位符</span></span><br><span class="line"></span><br><span class="line">y_hat = tf.nn.softmax(tf.matmul(x,W) + b) <span class="comment">#softmax激活</span></span><br><span class="line">cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_hat), reduction_indices=[<span class="number">1</span>])) <span class="comment">#成本函数</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(cost) <span class="comment">#梯度下降，最小化成本</span></span><br><span class="line"></span><br><span class="line">sess = tf.InteractiveSession() <span class="comment">#创建session</span></span><br><span class="line">tf.global_variables_initializer().run() <span class="comment">#初始化变量（声明了变量，就必须初始化才能用）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#迭代运算</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>) <span class="comment">#每次使用100个小批量数据</span></span><br><span class="line">    sess.run([train_step, cost], feed_dict = &#123;x: batch_xs, y: batch_ys&#125;) <span class="comment">#进行训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#计算准确率</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_hat,<span class="number">1</span>), tf.argmax(y,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"><span class="built_in">print</span>(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<p>最后用训练样本测试的准确率为92%左右。</p>
<h2 id="实现手势数字识别"><a href="#实现手势数字识别" class="headerlink" title="实现手势数字识别"></a>实现手势数字识别</h2><p>手势数字数据集中，训练样本有1080张图片，测试样本有120张图片，其中有代表着0-5的六种图片。每个原始样本由两部分组成，一个大小为64*64的手势数字图片像素值矩阵$x$以及它的标签$y$，原始样本的标签$y$是直接用手势图片表示的数字真实值表示的，还需要将它们转换为one-hot向量进行表示。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155438.png" alt="手势数字数据集"></p>
<h3 id="1-导入数据"><a href="#1-导入数据" class="headerlink" title="1.导入数据"></a>1.导入数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_dataset</span>():</span><br><span class="line">    train_dataset = h5py.File(<span class="string">&#x27;train_signs.h5&#x27;</span>, <span class="string">&quot;r&quot;</span>)<span class="comment">#训练集</span></span><br><span class="line">    train_set_x_orig = np.array(train_dataset[<span class="string">&quot;train_set_x&quot;</span>][:])</span><br><span class="line">    train_set_y_orig = np.array(train_dataset[<span class="string">&quot;train_set_y&quot;</span>][:])</span><br><span class="line"></span><br><span class="line">    test_dataset = h5py.File(<span class="string">&#x27;test_signs.h5&#x27;</span>, <span class="string">&quot;r&quot;</span>)<span class="comment">#测试集</span></span><br><span class="line">    test_set_x_orig = np.array(test_dataset[<span class="string">&quot;test_set_x&quot;</span>][:])</span><br><span class="line">    test_set_y_orig = np.array(test_dataset[<span class="string">&quot;test_set_y&quot;</span>][:])</span><br><span class="line"></span><br><span class="line">    classes = np.array(test_dataset[<span class="string">&quot;list_classes&quot;</span>][:])</span><br><span class="line"></span><br><span class="line">    train_set_y_orig = train_set_y_orig.reshape((<span class="number">1</span>, train_set_y_orig.shape[<span class="number">0</span>]))</span><br><span class="line">    test_set_y_orig = test_set_y_orig.reshape((<span class="number">1</span>, test_set_y_orig.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes</span><br></pre></td></tr></table></figure>
<h3 id="2-one-hot编码"><a href="#2-one-hot编码" class="headerlink" title="2.one-hot编码"></a>2.one-hot编码</h3><p>编码方式如图：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155453.png" alt="one-hot"></p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ong-hot编码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_to_one_hot</span>(<span class="params">Y, C</span>):</span><br><span class="line">    Y = np.eye(C)[Y.reshape(-<span class="number">1</span>)].T<span class="comment">#np.eye():生成单位矩阵</span></span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>

<h3 id="3-前向传播"><a href="#3-前向传播" class="headerlink" title="3.前向传播"></a>3.前向传播</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#前向传播</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_propagation</span>(<span class="params">X, parameters</span>):</span><br><span class="line"></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    b1 = parameters[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    b2 = parameters[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line">    W3 = parameters[<span class="string">&#x27;W3&#x27;</span>]</span><br><span class="line">    b3 = parameters[<span class="string">&#x27;b3&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    Z1 = tf.add(tf.matmul(W1,X),b1)                                           </span><br><span class="line">    A1 = tf.nn.relu(Z1)                                             </span><br><span class="line">    Z2 = tf.add(tf.matmul(W2,A1),b2)                                             </span><br><span class="line">    A2 = tf.nn.relu(Z2)                                            </span><br><span class="line">    Z3 = tf.add(tf.matmul(W3,A2),b3)                                                 </span><br><span class="line">    <span class="keyword">return</span> Z3</span><br></pre></td></tr></table></figure>

<h3 id="4-成本计算"><a href="#4-成本计算" class="headerlink" title="4.成本计算"></a>4.成本计算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#成本计算</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_cost</span>(<span class="params">Z3, Y</span>):</span><br><span class="line"></span><br><span class="line">    logits = tf.transpose(Z3)</span><br><span class="line">    labels = tf.transpose(Y)</span><br><span class="line"></span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))</span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<h3 id="5-整个模型"><a href="#5-整个模型" class="headerlink" title="5.整个模型"></a>5.整个模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model</span>(<span class="params">X_train, Y_train, X_test, Y_test, learning_rate = <span class="number">0.0001</span>, num_epochs = <span class="number">1500</span>, minibatch_size = <span class="number">32</span>, print_cost = <span class="literal">True</span></span>):</span><br><span class="line"></span><br><span class="line">    ops.reset_default_graph()  <span class="comment">#使重新运行时不覆盖tf的变量</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                             </span><br><span class="line">    seed = <span class="number">3</span>                                          </span><br><span class="line">    (n_x, m) = X_train.shape                          </span><br><span class="line">    n_y = Y_train.shape[<span class="number">0</span>]                            </span><br><span class="line">    costs = []                                        </span><br><span class="line"></span><br><span class="line">    X, Y = create_placeholders(n_x, n_y) <span class="comment">#占位符</span></span><br><span class="line">    parameters = initialize_parameters() <span class="comment">#初始化参数</span></span><br><span class="line">    Z3 = forward_propagation(X, parameters) <span class="comment">#前向传播</span></span><br><span class="line">    cost = compute_cost(Z3, Y) <span class="comment">#损失计算</span></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost) <span class="comment">#使用Adam梯度下降</span></span><br><span class="line"></span><br><span class="line">    init = tf.global_variables_initializer() <span class="comment">#变量初始化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"></span><br><span class="line">        sess.run(init) <span class="comment">#运行变量初始化</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line"></span><br><span class="line">            epoch_cost = <span class="number">0.</span> <span class="comment">#每epoch一次后的成本值</span></span><br><span class="line">            num_minibatches = <span class="built_in">int</span>(m / minibatch_size) <span class="comment">#小批量数目</span></span><br><span class="line">            seed = seed + <span class="number">1</span></span><br><span class="line">            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed) <span class="comment">#随机小批量</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line"></span><br><span class="line">                (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;)</span><br><span class="line">                epoch_cost += minibatch_cost / num_minibatches</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span> (<span class="string">&quot;%i epoch 后的成本值 : %f&quot;</span> % (epoch, epoch_cost))</span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(epoch_cost)</span><br><span class="line"></span><br><span class="line">        plt.plot(np.squeeze(costs))</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;cost&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;iterations (per tens)&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&quot;Learning rate =&quot;</span> + <span class="built_in">str</span>(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        parameters = sess.run(parameters)</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;参数训练完毕&quot;</span>)</span><br><span class="line"></span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))</span><br><span class="line"></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">&quot;float&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;训练集准确度:&quot;</span>, accuracy.<span class="built_in">eval</span>(&#123;X: X_train, Y: Y_train&#125;))</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;测试集准确度:&quot;</span>, accuracy.<span class="built_in">eval</span>(&#123;X: X_test, Y: Y_test&#125;))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<h3 id="6-得出结果"><a href="#6-得出结果" class="headerlink" title="6.得出结果"></a>6.得出结果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据集处理</span></span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line">X_train_flatten = X_train_orig.reshape(X_train_orig.shape[<span class="number">0</span>], -<span class="number">1</span>).T <span class="comment">#转置</span></span><br><span class="line">X_test_flatten = X_test_orig.reshape(X_test_orig.shape[<span class="number">0</span>], -<span class="number">1</span>).T</span><br><span class="line">X_train = X_train_flatten/<span class="number">255.</span> <span class="comment">#标准化</span></span><br><span class="line">X_test = X_test_flatten/<span class="number">255.</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>) <span class="comment">#变为one-hot形式</span></span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">parameters = model(X_train, Y_train, X_test, Y_test)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155521.png" alt="结果"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="http://mooc.study.163.com/course/deeplearning_ai-2001281003#/info">吴恩达-改善深层神经网络-网易云课堂</a></li>
<li><a target="_blank" rel="noopener" href="https://www.coursera.org/learn/deep-neural-network/">Andrew Ng-Improving Deep Neural Networks-Coursera</a></li>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/">tensorflow官网</a></li>
<li><a target="_blank" rel="noopener" href="http://www.tensorfly.cn/">tensorflow中文社区</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29903472">tensorflow环境搭建教程（Windows）</a></li>
<li><a target="_blank" rel="noopener" href="http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu16-04-geforce-gtx1080-tensorflow">tensorflow环境搭建教程（Ubuntu）</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Hugsy19/Machine_Learning">课程代码与资料-GitHub</a></li>
</ol>
<p>注：本文涉及的图片及资料均整理翻译自Andrew Ng的Deep Learning系列课程，版权归其所有。翻译整理水平有限，如有不妥的地方欢迎指出。</p>
<hr>
<p>更新历史：</p>
<ul>
<li>2017.10.15 完成初稿</li>
<li>2018.02.13 调整部分内容</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>深度学习(5)：TensorFlow</p><p><a href="https://hugsy.top/2017/10/14/ML/deep_learning_5/">https://hugsy.top/2017/10/14/ML/deep_learning_5/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hugsy</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2017-10-14</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-12-10</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/ML/">ML</a><a class="link-muted mr-2" rel="tag" href="/tags/Python/">Python</a></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><div class="social-share"></div><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210410180700.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210410180901.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2017/11/09/ML/deep_learning_6/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">深度学习(6)：结构化机器学习项目</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2017/10/06/ML/deep_learning_4/"><span class="level-item">深度学习(4)：优化神经网络(2)</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "67e389e814a74fa4861f69fe5b4cbf4b",
            repo: "Picbed",
            owner: "Hugsy19",
            clientID: "a321e46c668dc3d86c4f",
            clientSecret: "0ff9e81865b09e7511ef7ef17bb9596834b8fd95",
            admin: ["Hugsy19"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            proxy: "https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token",
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/logo.svg" alt="Cornfield Chase" height="28"></a><p class="is-size-7"><span>&copy; 2022 Hugsy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>
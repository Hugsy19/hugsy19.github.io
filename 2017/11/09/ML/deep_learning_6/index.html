<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>深度学习(6)：结构化机器学习项目 - Cornfield Chase</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#B481BB"><meta name="application-name" content="Hugsy&#039;s Blog"><meta name="msapplication-TileImage" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><meta name="msapplication-TileColor" content="#B481BB"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hugsy&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><meta name="description" content="构建好一个机器学习系统并获得一些初步结果时，为得到最令人满意的结果，后续往往还需要进行大量的改进。如前面优化神经网络中所述，改进的方法多种多样，可能是收集更多的数据，或者是进行正则化，或者是采用不同的优化算法。 想要找准改进的方向，使一个机器学习系统更快更有效地工作，需要学习一些在构建机器学习系统时常用到的策略。"><meta property="og:type" content="blog"><meta property="og:title" content="深度学习(6)：结构化机器学习项目"><meta property="og:url" content="https://hugsy.top/2017/11/09/ML/deep_learning_6/"><meta property="og:site_name" content="Cornfield Chase"><meta property="og:description" content="构建好一个机器学习系统并获得一些初步结果时，为得到最令人满意的结果，后续往往还需要进行大量的改进。如前面优化神经网络中所述，改进的方法多种多样，可能是收集更多的数据，或者是进行正则化，或者是采用不同的优化算法。 想要找准改进的方向，使一个机器学习系统更快更有效地工作，需要学习一些在构建机器学习系统时常用到的策略。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"><meta property="article:published_time" content="2017-11-08T16:00:00.000Z"><meta property="article:modified_time" content="2022-06-08T14:40:03.305Z"><meta property="article:author" content="Hugsy"><meta property="article:tag" content="ML"><meta property="article:tag" content="Coursera"><meta property="article:tag" content="Deep Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hugsy.top/2017/11/09/ML/deep_learning_6/"},"headline":"深度学习(6)：结构化机器学习项目","image":["https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png"],"datePublished":"2017-11-08T16:00:00.000Z","dateModified":"2022-06-08T14:40:03.305Z","author":{"@type":"Person","name":"Hugsy"},"description":"构建好一个机器学习系统并获得一些初步结果时，为得到最令人满意的结果，后续往往还需要进行大量的改进。如前面优化神经网络中所述，改进的方法多种多样，可能是收集更多的数据，或者是进行正则化，或者是采用不同的优化算法。 想要找准改进的方向，使一个机器学习系统更快更有效地工作，需要学习一些在构建机器学习系统时常用到的策略。"}</script><link rel="canonical" href="https://hugsy.top/2017/11/09/ML/deep_learning_6/"><link rel="alternate" href="/atom.xml" title="Cornfield Chase" type="application/atom+xml"><link rel="icon" href="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?7b65ce26b5ae8dae153d7b4d53214ba4";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/logo.svg" alt="Cornfield Chase" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/tags/CS/">CS</a><a class="navbar-item" href="/tags/EE/">EE</a><a class="navbar-item" href="/tags/ML/">ML</a><a class="navbar-item" href="/tags/ME/">ME</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411115030.png" alt="深度学习(6)：结构化机器学习项目"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2017-11-08T16:00:00.000Z" title="11/9/2017, 12:00:00 AM">2017-11-09</time>发表</span><span class="level-item"><time dateTime="2022-06-08T14:40:03.305Z" title="6/8/2022, 10:40:03 PM">2022-06-08</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">41 分钟读完 (大约6125个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">深度学习(6)：结构化机器学习项目</h1><div class="content"><p>构建好一个机器学习系统并获得一些初步结果时，为得到最令人满意的结果，后续往往还需要进行大量的改进。如前面优化神经网络中所述，改进的方法多种多样，可能是收集更多的数据，或者是进行正则化，或者是采用不同的优化算法。</p>
<p>想要找准改进的方向，使一个机器学习系统更快更有效地工作，需要学习一些在构建机器学习系统时常用到的策略。</p>
<span id="more"></span>

<h2 id="正交化"><a href="#正交化" class="headerlink" title="正交化"></a>正交化</h2><p>构建机器学习系统的挑战之一就是其中有很多你可以尝试、更改的东西，例如，其中有很多的超参数需要进行训练。把握好尝试、更改的方向，认识到进行的调整将带来的影响，是十分关键的。</p>
<p><strong>正交化（Orthogonalization）</strong>是确保修改一个系统中的某个算法指令或者组件时，不会产生或传播副作用到系统种的其他组件的一种系统设计属性。它使得验证一个算法独立于另一个算法时变得更加容易，同时也能减少设计和开发的时间。</p>
<p>例如在学习驾驶一辆汽车时，主要是在学习转向、加速、制动这三个基本的控制方法，这三种控制手段互不干扰，你只要通过不断得训练，熟练掌握它们就好。而假如要你去学会驾驶一辆只带一根操纵杆的汽车，操纵杆设计好了每操作一下就控制一定的转角、一定的速度，这时学习成本就大了很多。所谓的正交化，就是这个道理。</p>
<p>当设计一个监督学习系统，需做到符合下面四个假设且它们是正交的：</p>
<ol>
<li>建立的模型在训练集上表现良好；</li>
<li>建立的模型在开发集（验证集）上表现良好；</li>
<li>建立的模型在测试集上表现良好；</li>
<li>建立的模型在实际的应用中表现良好。</li>
</ol>
<p>当做到正交化时，如果发现</p>
<ol>
<li>训练集上表现不够好–尝试采用更大的神经网络或者换一种更好的优化算法；</li>
<li>验证集上表现不够好–尝试进行正则化处理或者加入更多训练数据；</li>
<li>测试集上表现不够好–尝试采用更大的验证集进行验证；</li>
<li>现实应用中表现不够好–可能是因为测试集没有设置正确或者成本函数评估出错。</li>
</ol>
<p>面对遇到的各种问题，正交化能够帮助我们更为精准地定位及有效地解决问题。</p>
<h2 id="找准目标"><a href="#找准目标" class="headerlink" title="找准目标"></a>找准目标</h2><h3 id="单一数字评估"><a href="#单一数字评估" class="headerlink" title="单一数字评估"></a>单一数字评估</h3><p>构建机器学习系统时，通过设置一个<strong>单一数字评估指标（single-number evaluation metric）</strong>，可以更为快速地判断出在经过几次调整后得到的不同结果里，哪个的效果要好些。</p>
<p>对于一个分类器，评价分类器性能的指标一般是分类的<strong>准确率（Accuracy）</strong>，也就是正确分类的样本数和总样本数之比，它也就可以作为一个单一数字估计指标。例如之前的猫分类器的几个算法都是通过准确率作其性能好坏的标准。</p>
<p>对于二分类问题常用的评价指标是<strong>精确率（Precision）</strong>和<strong>召回率（Recall）</strong>，将所关注的类作为<strong>正类（Positive）</strong>，其他的类为<strong>负类（Negative）</strong>，分类器在数据集上预测正确或不正确，4种情况出现的种数分别记为：</p>
<ul>
<li>TP（True Positive）——将正类预测为正类数</li>
<li>FN（False Negative）——将正类预测为负类数</li>
<li>FP（False Positive）——将负类预测为正类数</li>
<li>TN（Ture Negative）——将负类预测为负类数</li>
</ul>
<p>将精准率定义为：$$ P = \frac{TP}{TP + FP} $$<br>召回率定义为：$$ R = \frac{TP}{TP + FN} $$</p>
<p>而当遇到以下这种情况不好判别时，就需要采用<strong>F1度量（F1 Score）</strong>来判断两个分类器的好坏。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155745.png" alt="模糊情况"></p>
<p>F1度量定义为：$$ F_1 = \frac{2}{\frac{1}{P} + \frac{1}{R}} = \frac{2TP}{2TP + FP + FN} $$</p>
<p>F1度量值其实就是精准率和召回率的<strong>调和平均数（Harmonic Mean）</strong>，它是一种基于其平均值改善的方法，比简单地取平均值效果要好。如此，算出上图种A分类器的F1度量值为92.4%，B分类器的为91.0%，从未得知A分类器效果好些。这里F1度量值就作为了单一数字评估指标。</p>
<h3 id="满足、优化指标"><a href="#满足、优化指标" class="headerlink" title="满足、优化指标"></a>满足、优化指标</h3><p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155759.png" alt="关心运行时间"></p>
<p>然而有时，评判的标准不限于一个单一数字评估指标。比如上图中的几个猫分类器，想同时关心它们各自的识别准确率和运行时间，但如果把这两个指标组合成一个单一数字评估指标的话，就不太好了。这时，就需要把一个指标作为<strong>优化指标（Optimizing Metric）</strong>，而另外的一些的作为<strong>满足指标（Satisficing Metric）</strong>。</p>
<p>如上面所举的例子中，准确率就是一个优化指标，因为想要分类器尽可能做到正确分类，而运行时间就是一个满足指标，如果你想要分类器的运行时间不多于某个值，那你需要选择的分类器就应该是以这个值为界里面准确率最高的那个，以此作出权衡。</p>
<p>除了采用这些标准来评判一个模型外，也要学会在必要时及时地调整一些评判指标，甚至是更换训练数据。例如两个猫分类器A和B的识别误差分别为3%和5%，但是处于某种原因，A识别器会把色情图片误识为猫，引起用户的不适，而B不会出现这种情况，这时，识别误差大一些的B反而是更好的分类器。可以用以下公式来计算错误识别率：$$ Error: \frac{1}{m} \sum_{i=1}^m \mathcal{L} \{ {\hat{y}}^{i} \neq y^{i}\}\ $$</p>
<p>还可以设置一个$w^{(i)}$，当$x^{(i)}$是色情图片时，$w^{(i)}$为10，否则为1，以此来区分色情图片及其他误识别的图片：<br>$$ Error: \frac{1}{\sum w^{(i)}} \sum_{i=1}^m w^{(i)} \mathcal{L} \{ {\hat{y}}^{i} \neq y^{i}\}\ $$</p>
<p>所以要根据实际情况，正确确定一个评判指标，确保这个评判指标最优。</p>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p>构建机器学习系统时，对数据集的处理方法将影响你个整个构建过程中的进度。通过前面已经知道，一般把收集到的现有数据分为训练集、开发集和测试集，其中开发集也称为交叉验证集。构建机器学习系统时，采用一些不同的方法，在训练集上训练出不同的模型，随后使用开发集对模型的好坏进行评估，确信某个模型效果足够好时再用测试集进行测试。</p>
<p>首先需要注意的是，开发集和测试集的来源应该是相同的，且必须从所有数据中随机抽取，选择的开发测试集也要尽可能和以后机器学习系统要面对的数据一致，这样才能做到尽可能不偏离目标。</p>
<p>其次需要注意每个数据集大小的划分。在早期的机器学习时代，对于你拥有的所有数据集，通常就是把其中的70%作为训练集，剩下的30%作为测试集；或者要加入开发集的话，就把60%作为训练集，开发、测试集各取20%。当获得的数据比较少的时候，这种划分是合理的。但到了现在的机器学习时代，获得的数据数量一般都是成千上万的，这时就不能按传统的数据划分法来划分了。</p>
<p>假如获得了一百万个数据样本，将其中98%的数据都作为训练集，而只要将1%的也就是一万个数据作为开发集，1%的数据作为测试集就足够了。所以要根据实际情况，进行数据划分，而不是死板地遵循着传统。测试集的大小应该设置得足够提高系统整体性能得可信度，开发集的大小也要设置得足够用于评估几个不同的模型。</p>
<h2 id="比较人类表现水平"><a href="#比较人类表现水平" class="headerlink" title="比较人类表现水平"></a>比较人类表现水平</h2><p>如今，设计和建立一个机器学习系统比以前变得更为简单高效，一些机器学习算法的在很多领域的表现已经可以和我们人类一决高下了，例如之前由Google DeepMind公司开发的声名全球AlphaGo。然而，很多任务对于我们人类来说，都能够几近完美地完成，达到人类的表现水平便是机器学习试图去模仿、实现的。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155814.png" alt="人类表现水平"></p>
<p>上图展示了随着时间的推进机器学习和人的表现水平的变化，一般的，当机器学习超过人的表现水平后，它就进步地很缓慢了，其中有一个重要的原因是人类的对于一些自然感知问题的表现水平几近于<strong>贝叶斯误差（Bayes Error）</strong>。贝叶斯误差被定义为最优的可能误差，换句话说，就是任何从x到精确度y映射的函数都不可能超过这个值。</p>
<p>当建立的机器学习模型的表现还没达到人类的表现水平时，可以通过各种手段来提升它。例如采用人工标记过的数据进行训练，通过人工误差分析了解为什么人能够正确识别，或者是进行误差、偏差分析。</p>
<p>在优化神经网络中曾涉及过偏差和方差的概念，通过与人类在某件事情上的表现水平向比较，可以清楚地表明一个机器学习模型对此的表现的好坏程度，由此作出判断出后续应该进行减小偏差还是减小方差。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155827.png" alt="可避免偏差"></p>
<p>训练集的误差和人类表现水平的误差的差值就称为<strong>可避免偏差（Avoidable Bias）</strong>。例如上图中的两个场景下，将人的错误率和机器学习模型的错误率进行比较，看以看出在A场景下，学习算法的错误率和人的错误率的可避免偏差较大，这种情况下后续的工作就是通过之前介绍过的方法来降低训练集的错误率，以减小偏差。而在B场景下，学习算法和人的表现相当，偏可避免偏差只有0.5%，，后续的工作就应该转向尽可能地减小开发集和训练集那部分2%的方差。</p>
<p>人类表现水平给了我们一种估计贝叶斯误差的方式，而不是之前的将训练的错误率直接对着0%的方向进行优化。所以在获取到某项任务的人为误差数据时，就可以将这些数据作为贝叶斯误差的代理，以此来分析学习算法的偏差及方差。如果训练集与人类表现水平之间的误差差值大于训练集与开发集之间的差值，往后就应该专注于降低偏差，反之，就应该专注于降低方差。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155840.png" alt="减小偏差、方差方法"></p>
<p>上图中总结出了各种应对偏差及方差的方法。总之，可避免偏差低便意味着你的训练过程做的很好，可接受范围内的方差意味着你的模型在开发、测试集上的表现与训练集上同样好。</p>
<p>此外，如果出现可避免误差为负值，也就是机器学习模型的表现超过人类表现水平即贝叶斯误差的代理的情况时，并不意味着你的模型的性能已经达到极点了，往后想要再提高就要另寻一些常规方法了。现在机器学习在很多领域已经做到这一点了，例如进行在线广告业务、产品推销、预测物流运输时间、信用评估等等。</p>
<h2 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h2><p>当使用一个学习算法做人类可以做的任务时，如果这个学习算法还达不到人类去做时的性能，通过人工检查算法得出的结果中出现的一些错误，可以使你深入了解下一步要进行的工作，这个过程便称为错误分析。</p>
<p>比如对于一个猫分类器，在开发组里你已经取得了90%的识别准确率，还存在10%的出错率，而且还发现分类器会将一些看起来像猫的狗的图片误识别为猫，这时就不是立即盲目地转向去做一个能够精确识别出狗的算法，而是先进行错误分析。可以先把学习算法标签错误的图片找出来，然后进行人工检查，假如100张错误标签的图片中有5张是狗的图片，那么也就表明你的学习算法的10%的错误中大致只有5%来自于狗，也就是0.5%的错误来自于狗，这表明改善狗的识别问题并不能给你的学习算法带来多大提升。但如果100张错误标签的图片中有50张是狗的图片，也就是5%的错误是狗产生的，那么对于狗的识别就是你要解决的问题了。这样，先通过少量的时间去分析问题，再决定后面的要进行大方向。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155858.png" alt="表格分析"></p>
<p>在对输出结果中错误标签的样本进行人工分析时，常常可以建立一个表格，来记录每一个样本的一些情况，比如某些图像是模糊的，或者是把狗识别成了猫等等，以此来更加清楚地进行分析。</p>
<p>当发现输入的样本中，有一些样本是人为原因的错误标签，如果是在训练集中，只要这些出错的样本数量较小，分布地也比较随机，由于机器学习算法对于随机误差的<strong>稳健性（Robust）</strong>（也称“鲁棒性”），就不必花时间去一一修正它们；如果出现在开发集或者测试集，就可以在进行误差分析的时候，将这种情况对你的识别准确率的影响作出大致分析，这样对于是否值得去将输入中的错误标记一一进行修正，就有个明确的答案了。</p>
<p>总结一下：在构建一个机器学习系统时，尽可能按照以下几点来做：</p>
<ol>
<li>设置好训练、开发、测试集及衡量指标，找准目标；</li>
<li>快速构建出一个初步的系统，用训练集来拟合参数，开发集调参，测试集评估；</li>
<li>采用方差/偏差分析或者错误分析等方法来决定下一步工作。</li>
</ol>
<h2 id="不匹配的数据集"><a href="#不匹配的数据集" class="headerlink" title="不匹配的数据集"></a>不匹配的数据集</h2><p>对于获取的数据集，前面一直在强调训练、开发、测试集的来源都应该要是相同的。在无法达成这一要求下，对于不同来源的数据集，就要充分考虑如何将它们进行划分。</p>
<p>想要开发一款手机应用，就像现在的Google相册中分类功能一样，能对用户上传的猫的图片进行识别。假如现在有1万张普通用户上传的猫的图片数据，这些图片的质量都不太好，有一些可能是模糊的，另外又网络上获取了20万张质量较好的猫的图片。</p>
<p>构建机器学习模型时，在开发集和测试集上，一定要反映出将来需要面临的数据。考虑到例子中这个机器学习模型主要将应用在识别用户拍摄的猫的图片上，在划分数据上，就可以将20万张网络获取和图片和5千张用户上传的图片共20.5万张图片作为训练集，剩下的5千张图片一半作开发集，一半作测试集。长远来看，这种分配方法比起随机打乱所有数据样本再进行分配性能要好。</p>
<p>在这种情况下，由于数据集的不匹配，后续如果进行方差/偏差分析，就很难找到问题的根源了，例如对于上面的例子，由于开发集包含的样本比训练集中的样本更加难以准确识别，开发集的错误率往往会大于训练集的错误率。为了解决这个问题，可以再定义一个训练-开发集，训练-开发集和训练集的来源相同，但是这部分并不参与训练。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155913.png" alt="训练-开发集"></p>
<p>如上图所示，加入训练-开发集后得到的数据中，在B场景下训练集错误率和训练-开发集之间相差较大，它们的来源相同，由此就可以知道这是个偏差问题，后面各个场景下都可以按照之前的偏差/方差分析进行分析了，训练-开发集便起到了这个作用。</p>
<p>对于不匹配的数据集，偏差/方差分析过程如下：</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155932.png" alt="偏差/方差分析"></p>
<p>在一些情况下，可以直接通过一些手段直接解决数据集不匹配的问题。首先，需要进行人工错误分析，以了解训练、开发、测试集之间存在的差异，随后根据分析结果制作一些数据或者收集之间互相匹配的数据集。例如，必要是可以进行人工合成，将一些高质量的照片模糊化，或者对一些声音信息加入一些噪音，以此来使数据集匹配。</p>
<h2 id="多任务和端对端学习"><a href="#多任务和端对端学习" class="headerlink" title="多任务和端对端学习"></a>多任务和端对端学习</h2><h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p><strong>迁移学习（Tranfer Learning）</strong>是将一个神经网络从一个任务中学到的知识和经验，运用到另一个任务中。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411155953.png" alt="迁移学习"></p>
<p>如上图中，将为猫识别器构建的神经网络迁移应用到放射诊断中，因为猫识别器的神经网络已经学习到了关于图像的结构和性质等方面的知识，所以只要先删除神经网络的中最后一层，输出层的权重值也改为随机初始化的值，随后输入新的训练数据进行训练，就完成了以上的迁移学习。如果重新训练神经网络中的所有参数，则在这个图像识别的初始阶段称为预训练（Pre-Training）,它将预先初始化各个神经网络的权重值，之后的权重更新过程便称为微调（Fine-Tuning）。</p>
<p>符合下面的条件时，进行迁移学习才是有意义的：</p>
<ol>
<li>两个任务使用的数据集相同；</li>
<li>拥有更多数据的任务到数据较少的任务；</li>
<li>任务底层神经网络的某些功能对另一个任务有帮助。</li>
</ol>
<h3 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h3><p><strong>多任务学习（Multi-Task Learning）</strong>是采用一个神经网络来同时执行多个任务，且这些任务的执行可以相互促进。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411160012.png" alt="多任务学习"></p>
<p>在自动驾驶技术中，车辆必须同时检测视野范围内的各种物体，这时就要用到多任务学习，训练一个神经网络来检测多种物体，这样可以做到一些早期特征在不同类型的对象间共享。假如要同时识别行人、汽车、路标、交通灯，则上图片的标签将表示为：$$ y^{(i)} = \begin{bmatrix}<br>0\<br>1\<br>1\<br>0\<br>\end{bmatrix} $$<br>其中每一行分别表示四个要识别的物体，0或1代表无或有。其中的某些项目就算没有标记出来，并不产生影响。</p>
<p>神经网络的结构和损失函数将如下图所示:</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411160110.png" alt="神经网络结构"></p>
<p>符合下面的条件时，采用多任务学习才是有意义的：</p>
<ol>
<li>进行的任务都能从共享的较低级别功能中受益；</li>
<li>对每个任务拥有的数据量相当；</li>
<li>有能力训练足够大的神经网络来完成所有任务。</li>
</ol>
<h3 id="端到端学习"><a href="#端到端学习" class="headerlink" title="端到端学习"></a>端到端学习</h3><p><strong>端到端深度学习（End-to-end Deep Learning）</strong>是将处理或学习系统简化为一个神经网络。</p>
<p><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210411160124.png" alt="端到端机器学习"></p>
<p>如图，传统的语音识别系统，是由声学模型、词典、语言模型构成，而其中的语音模型和语言模型是分别训练的，而不同的语言也有不同的语言模型，比如英语和中文。而端到端的语音识别系统，从语音特征（输入端）到文字串（输出端）中间就只需要一个神经网络模型。</p>
<p>端到端深度学习并不能应用于每一个问题，因为它需要大量的标记数据。它主要应用于音频转录，图像捕捉，图像合成，机器翻译，自驾车转向等。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="http://mooc.study.163.com/course/2001280004#/info">吴恩达-结构化机器学习项目-网易云课堂</a></li>
<li><a target="_blank" rel="noopener" href="https://www.coursera.org/learn/machine-learning-projects/">Andrew Ng-Structuring Machine Learning Projects-Coursera</a></li>
<li>Andrew Ng-Machine Learning Yearning  </li>
<li><a target="_blank" rel="noopener" href="http://mini.eastday.com/a/161228171458937.html">端到端学习究竟是什么?</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Hugsy19/Machine_Learning">课程代码与资料-GitHub</a></li>
</ol>
<p>注：本文涉及的图片及资料均整理翻译自Andrew Ng的Deep Learning系列课程，版权归其所有。翻译整理水平有限，如有不妥的地方欢迎指出。</p>
<hr>
<p>更新历史：</p>
<ul>
<li>2017.11.18 完成初稿</li>
<li>2018.02.13 调整部分内容</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>深度学习(6)：结构化机器学习项目</p><p><a href="https://hugsy.top/2017/11/09/ML/deep_learning_6/">https://hugsy.top/2017/11/09/ML/deep_learning_6/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hugsy</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2017-11-09</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-06-08</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/ML/">ML</a><a class="link-muted mr-2" rel="tag" href="/tags/Coursera/">Coursera</a><a class="link-muted mr-2" rel="tag" href="/tags/Deep-Learning/">Deep Learning</a></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><div class="social-share"></div><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210410180700.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/20210410180901.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2017/11/19/EE/msc51_1/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">单片机原理(1)：基本结构</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2017/10/14/ML/deep_learning_5/"><span class="level-item">深度学习(5)：TensorFlow</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "8bfbe6b526a9ee3a4c761c50a5bcb8e9",
            repo: "Picbed",
            owner: "Hugsy19",
            clientID: "a321e46c668dc3d86c4f",
            clientSecret: "0ff9e81865b09e7511ef7ef17bb9596834b8fd95",
            admin: ["Hugsy19"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            proxy: "https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token",
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://raw.githubusercontent.com/Hugsy19/Picbed/master/img/logo.svg" alt="Cornfield Chase" height="28"></a><p class="is-size-7"><span>&copy; 2022 Hugsy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>